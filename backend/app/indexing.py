from pathlib import Path
from typing import Iterator, List
from dataclasses import dataclass
import ast

# –ü—É—Ç—å –¥–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞ (.../HaHaTone228_PAW_AI)
PROJECT_ROOT = Path(__file__).resolve().parents[2]
# –ü—É—Ç—å –¥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è reddit
REDDIT_ROOT = PROJECT_ROOT / "data" / "reddit"


def iter_code_files(root: Path, exts=(".py",)) -> Iterator[Path]:
    """
    –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º —Å –Ω—É–∂–Ω—ã–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ root.
    –°–µ–π—á–∞—Å —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å .py —Ñ–∞–π–ª–∞–º–∏.
    """
    for path in root.rglob("*"):
        if path.is_file() and path.suffix in exts:
            yield path


@dataclass
class CodeChunk:
    """
    –û–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏–π –∫—É—Å–æ–∫ –∫–æ–¥–∞ (—Ñ—É–Ω–∫—Ü–∏—è –∏–ª–∏ –∫–ª–∞—Å—Å).
    """
    file_path: str   # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ reddit_repo
    start_line: int
    end_line: int
    kind: str        # "function" –∏–ª–∏ "class"
    name: str        # –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏/–∫–ª–∞—Å—Å–∞
    code: str        # —Ç–µ–∫—Å—Ç –∫–æ–¥–∞ —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞


def extract_chunks_from_python_file(path: Path) -> List[CodeChunk]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç .py —Ñ–∞–π–ª —á–µ—Ä–µ–∑ ast –∏ –¥–æ—Å—Ç–∞–µ—Ç –∏–∑ –Ω–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å—ã.
    """
    text = path.read_text(encoding="utf-8", errors="ignore")
    try:
        tree = ast.parse(text)
    except SyntaxError:
        # –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç –Ω–µ –ø–∞—Ä—Å–∏—Ç—å—Å—è ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        return []

    lines = text.splitlines()
    chunks: List[CodeChunk] = []

    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
            start = node.lineno
            end = getattr(node, "end_lineno", None) or start

            # –∑–∞—â–∏—Ç–∞ –æ—Ç –≤—ã—Ö–æ–¥–∞ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã
            start = max(start, 1)
            end = min(end, len(lines))

            code_lines = lines[start - 1:end]
            code = "\n".join(code_lines)

            kind = "class" if isinstance(node, ast.ClassDef) else "function"

            chunks.append(
                CodeChunk(
                    file_path=str(path.relative_to(REDDIT_ROOT)),
                    start_line=start,
                    end_line=end,
                    kind=kind,
                    name=node.name,
                    code=code,
                )
            )

    return chunks


def collect_all_chunks(limit_files: int | None = None) -> List[CodeChunk]:
    """
    –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º .py —Ñ–∞–π–ª–∞–º –≤ reddit_repo –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —á–∞–Ω–∫–∏.
    limit_files ‚Äî –º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.
    """
    if not REDDIT_ROOT.exists():
        print(f"reddit_repo not found: {REDDIT_ROOT}")
        return []

    all_chunks: List[CodeChunk] = []
    total_files = 0
    files_with_chunks = 0

    for i, path in enumerate(iter_code_files(REDDIT_ROOT)):
        if limit_files is not None and i >= limit_files:
            break

        total_files += 1
        chunks = extract_chunks_from_python_file(path)
        if chunks:
            files_with_chunks += 1
        all_chunks.extend(chunks)

    print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ .py –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_files}")
    print(f"–§–∞–π–ª–æ–≤, –≥–¥–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ñ—É–Ω–∫—Ü–∏–∏/–∫–ª–∞—Å—Å—ã: {files_with_chunks}")
    print(f"–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ (—Ñ—É–Ω–∫—Ü–∏–π/–∫–ª–∞—Å—Å–æ–≤): {len(all_chunks)}")

    return all_chunks


def debug_one_file_with_chunks():
    """
    –ù–∞–π—Ç–∏ –ø–µ—Ä–≤—ã–π .py —Ñ–∞–π–ª, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å —á–∞–Ω–∫–∏, –∏ –≤—ã–≤–µ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ.
    """
    if not REDDIT_ROOT.exists():
        print(f"reddit_repo not found: {REDDIT_ROOT}")
        return

    for path in iter_code_files(REDDIT_ROOT):
        chunks = extract_chunks_from_python_file(path)
        if not chunks:
            continue

        print(f"FILE: {path}")
        print(f"–ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}\n")

        for ch in chunks[:5]:
            print("-" * 60)
            print(f"{ch.kind.upper()} {ch.name} ({ch.start_line}-{ch.end_line})")
            print(ch.code)
            print()
        break
    else:
        print("–í–æ–æ–±—â–µ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏/–∫–ª–∞—Å—Å–∞–º–∏ ü§î")




def build_reddit_index():
    """
    –°–æ–±—Ä–∞—Ç—å –≤—Å–µ python-—á–∞–Ω–∫–∏ –∏ –∑–∞–ø–∏—Å–∞—Ç—å –∏—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É.
    """
    #–ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–µ–ª–∞–µ–º
    from .vector_store import build_index  # –∏–º–ø–æ—Ä—Ç –≤ –∫–æ–Ω—Ü–µ, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Ü–∏–∫–ª–æ–≤

    chunks = collect_all_chunks()
    if not chunks:
        print("–ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏–Ω–¥–µ–∫—Å –Ω–µ —Å—Ç—Ä–æ–∏–º")
        return

    print("–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
    build_index(chunks)
    print("–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω.")


if __name__ == "__main__":
    build_reddit_index()

    #–î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å:
    # collect_all_chunks()
    # debug_one_file_with_chunks()

    # –î–ª—è –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º:
    #collect_all_chunks()

    # –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–µ—Ä–≤—ã—Ö —á–∞–Ω–∫–æ–≤ –∏–∑ –∫–∞–∫–æ–≥–æ-–Ω–∏–±—É–¥—å —Ñ–∞–π–ª–∞:
    # debug_one_file_with_chunks()